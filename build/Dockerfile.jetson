ARG L4T_TAG=r36.2.0
FROM nvcr.io/nvidia/l4t-jetpack:${L4T_TAG}
ENV NVIDIA_VISIBLE_DEVICES=all
ENV NVIDIA_DRIVER_CAPABILITIES=compute,utility
WORKDIR /workspace

# System deps (add libnuma-dev!)
RUN apt-get update && apt-get install -y --no-install-recommends \
    python3 python3-pip python3-venv python3-dev \
    git git-lfs build-essential cmake ninja-build \
    libprotobuf-dev protobuf-compiler \
    libcurl4-openssl-dev \
    libnvinfer-dev libnvinfer-plugin-dev python3-libnvinfer \
    pybind11-dev \
    libnuma-dev \
 && apt-get clean && rm -rf /var/lib/apt/lists/*

RUN python3 -m pip install --no-cache-dir --upgrade pip setuptools wheel

# Your repo
COPY . /workspace

# TensorRT-LLM (no PyPI tensorrt)
RUN git clone --recursive --depth 1 https://github.com/NVIDIA/TensorRT-LLM.git /workspace/TensorRT-LLM

# Strip any tensorrt* from requirements to avoid PyPI
RUN sed -i '/^tensorrt[_a-zA-Z0-9-]*/d' /workspace/TensorRT-LLM/requirements.txt \
 && sed -i '/^tensorrt[_a-zA-Z0-9-]*/d' /workspace/TensorRT-LLM/requirements-dev.txt

# Preinstall cleaned requirements
RUN python3 -m pip install --no-cache-dir -r /workspace/TensorRT-LLM/requirements.txt --no-deps \
 && python3 -m pip install --no-cache-dir -r /workspace/TensorRT-LLM/requirements-dev.txt --no-deps

# Make Conan non-interactive and generate a profile
ENV CONAN_NON_INTERACTIVE=1
RUN conan profile detect --force || true

# Build & install the TRT-LLM wheel
ENV CUDACXX=/usr/local/cuda/bin/nvcc
RUN cd /workspace/TensorRT-LLM && \
    python3 scripts/build_wheel.py \
      --build_type Release \
      --job_count $(nproc) \
      --no-venv && \
    python3 -m pip install --no-cache-dir dist/tensorrt_llm-*.whl --no-deps

CMD ["/bin/bash"]
