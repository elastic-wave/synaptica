FROM nvcr.io/nvidia/l4t-jetpack:r36.2.0

# Workdir
WORKDIR /workspace

# --- System tools & build deps (lean) ---
RUN apt-get update && DEBIAN_FRONTEND=noninteractive apt-get install -y --no-install-recommends \
    build-essential \
    git git-lfs \
    python3 python3-pip python3-dev \
    cmake \
    ninja-build \
    libnuma-dev \
    libprotobuf-dev protobuf-compiler \
    libcurl4-openssl-dev \
    libnvinfer-dev libnvinfer-plugin-dev libnvonnxparsers-dev libnvparsers-dev \
    pybind11-dev \
 && rm -rf /var/lib/apt/lists/*

# --- Modern CMake/Ninja/Conan in PATH ---
RUN python3 -m pip install --no-cache-dir --upgrade pip setuptools wheel "cmake>=3.27" "ninja>=1.11" "conan~=2.4"
ENV CONAN_NON_INTERACTIVE=1 \
    CUDACXX=/usr/local/cuda/bin/nvcc
RUN conan profile detect --force || true

# --- Fetch TensorRT-LLM (with submodules) ---
RUN git clone --recursive --depth 1 https://github.com/NVIDIA/TensorRT-LLM.git /workspace/TensorRT-LLM

# --- Make NCCL optional everywhere (some sub-CMake files also require it) ---
RUN grep -Rn "find_package( *NCCL" /workspace/TensorRT-LLM || true && \
    sed -i -E 's/find_package\(\s*NCCL\s+REQUIRED\s*\)/find_package(NCCL QUIET)/g' $(grep -RIl "find_package( *NCCL" /workspace/TensorRT-LLM)

# --- Prevent pip from trying to pull TensorRT wheels from PyPI ---
RUN sed -i '/^tensorrt[_a-zA-Z0-9-]*/d' /workspace/TensorRT-LLM/requirements.txt && \
    sed -i '/^tensorrt[_a-zA-Z0-9-]*/d' /workspace/TensorRT-LLM/requirements-dev.txt

# --- Pre-install cleaned Python requirements (no deps; use JetPack TRT in /usr) ---
RUN python3 -m pip install --no-cache-dir -r /workspace/TensorRT-LLM/requirements.txt --no-deps && \
    python3 -m pip install --no-cache-dir -r /workspace/TensorRT-LLM/requirements-dev.txt --no-deps

# --- Build & install TensorRT-LLM wheel (Single-GPU, NCCL disabled) ---
RUN rm -rf /workspace/TensorRT-LLM/cpp/build || true && \
    cd /workspace/TensorRT-LLM && \
    python3 scripts/build_wheel.py \
      --clean \
      --build_type Release \
      --job_count $(nproc) \
      --no-venv \
      --binding_type pybind \
      --cuda_architectures 87 \
      --trt_root /usr \
      --extra-cmake-vars CMAKE_PREFIX_PATH=/usr/lib/aarch64-linux-gnu/cmake/TensorRT \
      --extra-cmake-vars TRTLLM_USE_NCCL=OFF \
      --extra-cmake-vars TRTLLM_ENABLE_MULTI_GPU=OFF \
      --extra-cmake-vars BUILD_DEEP_GEMM=OFF \
      --extra-cmake-vars BUILD_DEEP_EP=OFF \
      --extra-cmake-vars BUILD_FLASH_MLA=OFF && \
    python3 -m pip install --no-cache-dir /workspace/TensorRT-LLM/dist/tensorrt_llm-*.whl --no-deps


# --- Default CMD for interactive use ---
CMD ["bash"]