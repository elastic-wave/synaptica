# build/Dockerfile.jetson
# Use the JetPack image that matches your L4T series. For 36.4.x, 36.3.0 is fine.
ARG L4T_TAG=r36.2.0
FROM nvcr.io/nvidia/l4t-jetpack:${L4T_TAG}

ENV NVIDIA_VISIBLE_DEVICES=all
ENV NVIDIA_DRIVER_CAPABILITIES=compute,utility
WORKDIR /workspace

# OS deps (lean + cleanup)
RUN apt-get update && apt-get install -y --no-install-recommends \
    python3 python3-pip python3-venv python3-dev \
    git build-essential cmake ninja-build \
    libprotobuf-dev protobuf-compiler \
    libcurl4-openssl-dev \
 && apt-get clean && rm -rf /var/lib/apt/lists/*

# Copy repo
COPY . /workspace

# Python deps (NO pip tensorrt!)
RUN python3 -m pip install --no-cache-dir --upgrade pip setuptools wheel \
 && python3 -m pip install --no-cache-dir numpy onnx onnxsim transformers tokenizers requests

# Install TensorRT-LLM WITHOUT deps so it wonâ€™t try to pull 'tensorrt' from PyPI
RUN git clone --depth 1 https://github.com/NVIDIA/TensorRT-LLM.git /workspace/TensorRT-LLM \
 && python3 -m pip install --no-cache-dir -r /workspace/TensorRT-LLM/requirements.txt --no-deps \
 && python3 -m pip install --no-cache-dir -e /workspace/TensorRT-LLM --no-deps

CMD ["/bin/bash"]
