# build/Dockerfile.jetson
ARG L4T_TAG=r36.3.0
FROM nvcr.io/nvidia/l4t-base:${L4T_TAG}

ENV NVIDIA_VISIBLE_DEVICES=all
ENV NVIDIA_DRIVER_CAPABILITIES=compute,utility

RUN apt-get update && apt-get install -y --no-install-recommends \
    python3 python3-pip python3-venv python3-dev \
    git build-essential cmake ninja-build \
    libprotobuf-dev protobuf-compiler \
    libcurl4-openssl-dev \
    && rm -rf /var/lib/apt/lists/*

RUN update-alternatives --install /usr/bin/python python /usr/bin/python3 1
WORKDIR /workspace
COPY . /workspace

# Core python deps
RUN pip install --no-cache-dir --upgrade pip setuptools wheel \
 && pip install --no-cache-dir numpy onnx onnxsim transformers tokenizers requests

# ---- TensorRT-LLM ----
# Try official wheel first (if available for your Jetson); if not, build from source.
# 1) Wheel path (uncomment if you have an index URL or wheel file):
# RUN pip install --no-cache-dir tensorrt_llm

# 2) Source path (generic and reliable):
RUN git clone --depth 1 https://github.com/NVIDIA/TensorRT-LLM.git /workspace/TensorRT-LLM \
 && pip install --no-cache-dir -e /workspace/TensorRT-LLM
